{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matlab-stuff  kaggle-house \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# save shape for splitting later\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a heatmap of the features\n",
    "corr = train.corr()\n",
    "#plt.subplots(figsize=(20, 20))\n",
    "#sns.heatmap(corr, cmap='rainbow', vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now concatenate the training and test data so we can fill in missing variables\n",
    "y_train = train.SalePrice.values\n",
    "allData = pd.concat((train, test)).reset_index(drop=True)\n",
    "allData.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "all_data_na = (allData.isnull().sum() / len(allData)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "\n",
    "missingDataPlot = pd.DataFrame({'Missing Ratio' : all_data_na})\n",
    "#missingDataPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in any NA values with \"None\" where it applies\n",
    "allData['PoolQC'] = allData['PoolQC'].fillna(\"None\")\n",
    "allData['MiscFeature'] = allData['MiscFeature'].fillna(\"None\")\n",
    "allData['Alley'] = allData['Alley'].fillna(\"None\")\n",
    "allData['Fence'] = allData['Fence'].fillna(\"None\")\n",
    "allData['FireplaceQu'] = allData['FireplaceQu'].fillna(\"None\")\n",
    "allData['BsmtExposure'] = allData['BsmtExposure'].fillna(\"None\")\n",
    "allData['BsmtCond'] = allData['BsmtCond'].fillna(\"None\")\n",
    "allData['BsmtQual'] = allData['BsmtQual'].fillna(\"None\")\n",
    "allData['BsmtFinType1'] = allData['BsmtFinType1'].fillna(\"None\")\n",
    "allData['BsmtFinType2'] = allData['BsmtFinType2'].fillna(\"None\")\n",
    "\n",
    "# Is this the best way to handle this (in this case, None = None)\n",
    "allData['MasVnrType'] = allData['MasVnrType'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoning is mixed type (objects etc). by forcing str, the fillna works again\n",
    "allData['MSZoning']=allData['MSZoning'].astype(str)\n",
    "allData['KitchenQual']=allData['KitchenQual'].astype(str)\n",
    "allData['Exterior1st']=allData['Exterior1st'].astype(str)\n",
    "allData['Exterior2nd']=allData['Exterior2nd'].astype(str)\n",
    "allData['Electrical']=allData['Electrical'].astype(str)\n",
    "# mszoning has a special \"nan\" that is not np.nan\n",
    "# allData['MSZoning'] = allData['MSZoning'].replace({\"nan\" : allData['MSZoning'].mode()},regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other features will require numerical data\n",
    "allData['GarageCars'] = allData['GarageCars'].fillna(0)\n",
    "allData['BsmtFullBath'] = allData['BsmtFullBath'].fillna(0)\n",
    "allData['BsmtHalfBath'] = allData['BsmtHalfBath'].fillna(0)\n",
    "allData['BsmtUnfSF'] = allData['BsmtUnfSF'].fillna(0)\n",
    "allData['TotalBsmtSF'] = allData['TotalBsmtSF'].fillna(0)\n",
    "allData['BsmtFinSF1'] = allData['TotalBsmtSF'].fillna(0)\n",
    "allData['BsmtFinSF2'] = allData['TotalBsmtSF'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features that may skew data if their missing data is filled with 0 or None\n",
    "allData.drop(['GarageArea'], axis=1, inplace=True)\n",
    "allData.drop(['GarageYrBlt'], axis=1, inplace=True)\n",
    "allData.drop(['GarageQual'], axis=1, inplace=True)\n",
    "allData.drop(['GarageCond'], axis=1, inplace=True)\n",
    "allData.drop(['GarageFinish'], axis=1, inplace=True)\n",
    "allData.drop(['GarageType'], axis=1, inplace=True)\n",
    "allData.drop(['MasVnrArea'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special Cases: LotFrontage, MSZoning, Utilities, Electrical, Exterior1st, Exterior2nd, Functional\n",
    "# For the following features, it may be safe to asusme that there is consistency within\n",
    "# the neighborhood. We can fill with a value based on the other houses in that neighborhood\n",
    "allData['LotFrontage'] = allData.groupby(\"Neighborhood\")['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "# TODO\n",
    "# Should this be mode of neighborhood?\n",
    "# Need to make sure that we are not filling in a nan value with nan\n",
    "allData['MSZoning'] = allData.groupby(\"Neighborhood\")['MSZoning'].transform(\n",
    "    lambda x: x.replace(\"nan\", x.mode()[0]))\n",
    "\n",
    "\n",
    "allData['Exterior2nd'] = allData.groupby(\"Neighborhood\")['Exterior2nd'].transform(\n",
    "    lambda x: x.replace(\"nan\", \"woogiewoogie\"))\n",
    "\n",
    "allData['Exterior1st'] = allData.groupby(\"Neighborhood\")['Exterior1st'].transform(\n",
    "    lambda x: x.replace(\"nan\", \"woogiewoogie\"))\n",
    "\n",
    "# allData['MSZoning'] = allData['MSZoning'].fillna(allData['MSZoning'].mode())\n",
    "\n",
    "# TODO\n",
    "# Should this be by year or neighborhood?\n",
    "allData['Electrical'] = allData.groupby(\"Neighborhood\")['Electrical'].transform(\n",
    "    lambda x: x.fillna(x.mode()))\n",
    "\n",
    "# TODO\n",
    "# Should these be mode of neighborhood?\n",
    "allData['Exterior1st'] = allData.groupby(\"Neighborhood\")['Exterior1st'].transform(\n",
    "    lambda x: x.fillna(x.mode()))\n",
    "allData['Exterior2nd'] = allData.groupby(\"Neighborhood\")['Exterior2nd'].transform(\n",
    "    lambda x: x.fillna(x.mode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data description states to assume  Typical funtionality unless otherwise stated\n",
    "allData['Functional'] = allData['Functional'].fillna(\"Typ\")\n",
    "\n",
    "# In data description, WD == Warranty Deed - Conventional\n",
    "allData['SaleType'] = allData['SaleType'].fillna(\"WD\")\n",
    "\n",
    "# For Utilities, the vast majority of the houses have the same value.\n",
    "missingDataPlot = [x for x in allData['Utilities'] if x != \"AllPub\"]\n",
    "#missingDataPlot\n",
    "\n",
    "# Only three of these houses do not have \"AllPub.\" \n",
    "# The \"NoSeWa\" is in the training set. \n",
    "# The feature is therefore useless to us for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Do we also drop the house that has NoSeWa?\n",
    "allData.drop(['Utilities'], axis=1, inplace=True)\n",
    "\n",
    "# Check one more time to make sure we have not missed any missing data\n",
    "nan_rows = allData[allData.isnull().T.any().T]\n",
    "#nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na = (allData.isnull().sum() / len(allData)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "\n",
    "missingDataPlot = pd.DataFrame({'Missing Ratio' : all_data_na})\n",
    "#missingDataPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'secretly ordinal' features into numerical ones, provide more data to the model\n",
    "has_rank = [col for col in allData if 'TA' in list(allData[col])]\n",
    "dic_num = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "allData['MSSubClass'] = allData['MSSubClass'].astype('category')\n",
    "\n",
    "for col in has_rank:\n",
    "    allData[col+'_2num'] = allData[col].map(dic_num)\n",
    "\n",
    "allData = pd.get_dummies(allData)\n",
    "d_cols = allData.select_dtypes(include=['number']).columns\n",
    "allData = allData[d_cols]\n",
    "allData = allData.fillna(allData.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify skew for numerical features\n",
    "cols = [col for col in allData if '_2num' in col or '_' not in col]\n",
    "skew = [abs(stats.skew(allData[col])) for col in allData if '_2num' in col or '_' not in col]\n",
    "skews = pd.DataFrame()\n",
    "skews['Columns'] = cols\n",
    "skews['Skew_Magnintudes'] = skew\n",
    "cols_unskew = skews[skews.Skew_Magnintudes > 1].Columns\n",
    "allData_unskew = allData.copy()\n",
    "\n",
    "# replace with log(n+1)\n",
    "for col in cols_unskew:\n",
    "    allData_unskew[col] = np.log1p(allData[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of annoying warning that we thought was an error\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Split the testing and training data back into two collections\n",
    "train = allData.query(\"Id < 1461\")\n",
    "train['SalePrice'] = y_train\n",
    "test = allData.query(\"Id >= 1461\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/linalg/linalg.py:1804: RuntimeWarning: overflow encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/statsmodels/stats/outliers_influence.py:323: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return  self.results.resid / sigma / np.sqrt(1 - hii)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/statsmodels/stats/multitest.py:147: RuntimeWarning: invalid value encountered in less_equal\n",
      "  reject = pvals <= alphacBonf\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/statsmodels/stats/multitest.py:251: RuntimeWarning: invalid value encountered in greater\n",
      "  pvals_corrected[pvals_corrected>1] = 1\n"
     ]
    }
   ],
   "source": [
    "# identify outliers (SLOW)\n",
    "X = train.drop(['SalePrice','Id'], axis = 1)\n",
    "model = sm.OLS(y_train,X)\n",
    "results = model.fit()\n",
    "bonf_test = results.outlier_test()['bonf(p)']\n",
    "bonf_outlier = list(bonf_test[bonf_test<1e-3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[197, 523, 691, 803, 825, 898, 1046, 1169, 1170, 1182, 1324, 1423]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG - display Id of outliers in training set\n",
    "bonf_outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers from training data\n",
    "train.drop(bonf_outlier, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- EXPORT CLEAN DATA ----------\n",
    "\n",
    "# Then write the data sets to a csv\n",
    "train.to_csv('p_train.csv')\n",
    "test.to_csv('p_test.csv')\n",
    "\n",
    "# check Id nums\n",
    "file = pd.read_csv('p_test.csv')\n",
    "#file[\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LINEAR REGRESSION ----------\n",
    "\n",
    "x_train = train.drop(['SalePrice', 'Id'], axis=1)\n",
    "x_test  = test.drop(['Id'], axis=1)\n",
    "\n",
    "# Random Forest Regressor\n",
    "rf_test = RandomForestRegressor(max_depth=30, n_estimators=500, max_features=100, oob_score=True, random_state=1234)\n",
    "rf_test.fit(x_train, y_train)\n",
    "preds_rf = rf_test.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB regressor\n",
    "xgb_test = XGBRegressor(learning_rate=0.05, n_estimators=500, max_depth=3, colsample_bytree=0.4)\n",
    "xgb_test.fit(x_train, y_train)\n",
    "preds_xgb = xgb_test.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV\n",
    "scaler = StandardScaler()\n",
    "LCV = LassoCV()\n",
    "scale_LCV = Pipeline([('scaler', scaler), ('LCV', LCV)])\n",
    "scale_LCV.fit(x_train, y_train)\n",
    "preds_lasso = scale_LCV.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the predictions of both regressors\n",
    "preds = (preds_xgb + preds_lasso + preds_rf)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- EXPORT PREDICTIONS ----------\n",
    "out_preds = pd.DataFrame()\n",
    "out_preds['Id'] = test['Id']\n",
    "out_preds['SalePrice'] = preds\n",
    "out_preds.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
